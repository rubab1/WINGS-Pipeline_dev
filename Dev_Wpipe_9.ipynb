{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "import time, subprocess, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('io.hdf.default_format','table')\n",
    "\n",
    "# path_to_store='/Users/ben/src/WINGS/wings_pipe/h5data/wpipe_store.h5'\n",
    "path_to_store='/Users/rubab/Work/WINGS/wings_pipe/h5data/wpipe_store.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rubab/anaconda/envs/astroconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "def update_time(x):\n",
    "    x.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "    return x\n",
    "\n",
    "def increment(df,x):\n",
    "    df[x] = int(df[x])+1\n",
    "    return df\n",
    "\n",
    "def _min_itemsize(x):\n",
    "    min_itemsize = {}\n",
    "    for k,_dt in dict(x.dtypes).items():\n",
    "        if _dt is np.dtype('O'):\n",
    "            min_itemsize[k] = int(256)\n",
    "    return min_itemsize\n",
    "\n",
    "class Store():\n",
    "    def __init__(self,storePath=path_to_store):\n",
    "        self.path = str(storePath)\n",
    "        return None\n",
    "    \n",
    "    def new(self):\n",
    "        _dict = {'users': User().new(),\n",
    "                 'nodes': Node().new(),\n",
    "                 'options': Options().new(),\n",
    "                 'pipelines': Pipeline().new(),\n",
    "                 'targets': Target().new(),\n",
    "                 'configurations': Configuration().new(),\n",
    "                 'data_products': DataProduct().new(),\n",
    "                 'parameters': Parameters().new(),\n",
    "                 'tasks': Task().new(),\n",
    "                 'jobs': Job().new(),\n",
    "                 'masks':  Mask().new(),\n",
    "                 'events': Event().new()}\n",
    "        with pd.HDFStore(str(self.path),'w',complevel=9,\n",
    "                    complib='blosc:blosclz') as myStore:\n",
    "            for k,v in _dict.items():\n",
    "                myStore.append(k,v,min_itemsize=_min_itemsize(v),\n",
    "                          complevel=9,complib='blosc:blosclz')\n",
    "        return None\n",
    "\n",
    "    def create(self,key,name_id,stuff):\n",
    "        with pd.HDFStore(str(self.path),'r+') as myStore:\n",
    "            stuff.__dict__[name_id][0] = int(myStore[key][name_id].max())+1\n",
    "            newStuff = stuff.new()\n",
    "            myStore.append(key,newStuff,min_itemsize=_min_itemsize(newStuff),\n",
    "                          complevel=9,complib='blosc:blosclz')\n",
    "        return newStuff\n",
    "        \n",
    "    def update(self,key,stuff):\n",
    "        with pd.HDFStore(str(self.path),'r+') as myStore:\n",
    "            _t = myStore[key]\n",
    "            _t = _t.drop(index=stuff.index).append(stuff)\n",
    "            myStore.remove(key)\n",
    "            myStore.append(key,_t,min_itemsize=_min_itemsize(_t),\n",
    "                        complevel=9,complib='blosc:blosclz')\n",
    "        return None\n",
    "    \n",
    "    def select(self,key='events',where='all',columns=None):\n",
    "        with pd.HDFStore(str(self.path),'r') as myStore:\n",
    "            if where=='all':\n",
    "                if columns is None:\n",
    "                    return myStore.get(str(key))\n",
    "                else:\n",
    "                    return myStore.select(str(key),columns=columns)\n",
    "            else:\n",
    "                return myStore.select(str(key),columns=columns).query(str(where))\n",
    "            \n",
    "    def repack(self):\n",
    "        filename = str(self.path)\n",
    "        _t1 = ['cp', filename, './backup1.h5']\n",
    "        _t2 = ['ptrepack', '--chunkshape=auto', '--propindexes', '--complevel=9',\n",
    "               '--complib=blosc', filename, './temp1.h5']\n",
    "        _t3 = ['mv', './temp1.h5', filename]\n",
    "        _t = subprocess.run(_t1, stdout=subprocess.PIPE)\n",
    "        _t = subprocess.run(_t2, stdout=subprocess.PIPE)\n",
    "        _t = subprocess.run(_t3, stdout=subprocess.PIPE)\n",
    "        return\n",
    "                \n",
    "\n",
    "class User():\n",
    "    def __init__(self,name='any'):\n",
    "        self.name = np.array([str(name)],dtype='<U20')\n",
    "        self.user_id = np.array([int(0)])\n",
    "        self.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "        return None\n",
    "\n",
    "    def new(self):\n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = _df.user_id\n",
    "        return update_time(_df)\n",
    "\n",
    "    def create(self,store=Store()):\n",
    "        return store.create('users','user_id',self)\n",
    "\n",
    "    def get(user_name,store=Store()):\n",
    "        x = store.select('users','name==\"'+str(user_name)+'\"')\n",
    "        return x.loc[x.index.values[0]]\n",
    "    \n",
    "class Node():\n",
    "    def __init__(self,name='any',int_ip='',ext_ip=''):\n",
    "        self.name = np.array([str(name)])\n",
    "        self.node_id = np.array([int(0)])\n",
    "        self.int_ip = np.array([str(int_ip)])\n",
    "        self.ext_ip = np.array([str(ext_ip)])\n",
    "        self.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "        return None\n",
    "    \n",
    "    def new(self):\n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = _df.node_id\n",
    "        return update_time(_df)\n",
    "    \n",
    "    def create(self,store=Store()):\n",
    "        return store.create('nodes','node_id',self)\n",
    "\n",
    "    def get(node_id,store=Store()):\n",
    "        return store.select('nodes').loc[int(node_id)]\n",
    "    \n",
    "class Options():\n",
    "    def __init__(self,opts={'any':0}):\n",
    "        self.__dict__ = opts\n",
    "        return None\n",
    "\n",
    "    def new(self,owner=str('any'+250*' '),owner_id=0):\n",
    "        name = np.array(list(self.__dict__.keys()))\n",
    "        value = np.array(list(self.__dict__.values()))\n",
    "        _df = pd.DataFrame(data=np.array([name,value]).T,columns=\n",
    "                ['name','value']).sort_values('name')\n",
    "        owner = np.repeat(str(owner),len(name))\n",
    "        owner_id = np.repeat(int(owner_id),len(name))\n",
    "        arrays = [owner,owner_id]\n",
    "        _df.index = pd.MultiIndex.from_arrays(arrays, names=('owner','owner_id'))\n",
    "        return _df\n",
    "    \n",
    "    def create(self,owner='any',owner_id=0,store=Store()):\n",
    "        _df = self.new(owner,owner_id)\n",
    "        with pd.HDFStore(str(store.path),'r+') as myStore:\n",
    "            myStore.append('options',_df,min_itemsize=_min_itemsize(_df),\n",
    "                          complevel=9,complib='blosc:blosclz')\n",
    "        return _df\n",
    "\n",
    "    def get(owner,owner_id,store=Store()):\n",
    "        x = store.select('options').loc[str(owner)].loc[int(owner_id)]\n",
    "        if x.shape==(2,):\n",
    "            return dict(zip([x['name']],[x['value']]))\n",
    "        else:\n",
    "            return dict(zip(x['name'].values,x['value'].values))\n",
    "    \n",
    "    def addOption(owner,owner_id,key,value,store=Store()):\n",
    "        _opt = Options.get(owner,int(owner_id))\n",
    "        _opt[key] = value\n",
    "        return store.update('options',Options(_opt).new(owner,int(owner_id)))\n",
    "\n",
    "    \n",
    "class Pipeline():\n",
    "    def __init__(self,user=User().new(),name='any',software_root='',\n",
    "                 data_root='',pipe_root='',config_root='',\n",
    "                 description=''):\n",
    "        self.name = np.array([str(name)])\n",
    "        self.user_name = np.array([str(user['name'])])           \n",
    "        self.user_id = np.array([int(user.user_id)])\n",
    "        self.pipeline_id = np.array([int(0)])\n",
    "        self.software_root = np.array([str(software_root)])\n",
    "        self.data_root = np.array([str(data_root)])\n",
    "        self.pipe_root = np.array([str(pipe_root)])\n",
    "        self.config_root = np.array([str(config_root)])\n",
    "        self.description = np.array([str(description)])\n",
    "        self.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "        return None\n",
    "                                 \n",
    "    def new(self):\n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = _df.pipeline_id\n",
    "        return update_time(_df)\n",
    "\n",
    "    def create(self,store=Store()):\n",
    "        _df = store.create('pipelines','pipeline_id',self)       \n",
    "        return _df\n",
    "\n",
    "    def get(pipeline_id,store=Store()):\n",
    "        return store.select('pipelines').loc[int(pipeline_id)]    \n",
    "        \n",
    "class Target():\n",
    "    def __init__(self,name='any',\n",
    "                 pipeline=Pipeline().new()):               \n",
    "        self.name = np.array([str(name)])\n",
    "        self.pipeline_id = np.array([int(pipeline.pipeline_id)])\n",
    "        self.target_id = np.array([int(0)])\n",
    "        myPipe = Pipeline.get(self.pipeline_id)\n",
    "        self.relativepath = np.array([str(myPipe.data_root)+'/'+str(self.name[0])])\n",
    "        self.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "        return None\n",
    "\n",
    "    def new(self):\n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = pd.MultiIndex.from_arrays(arrays=[np.array([int(self.pipeline_id)]),\n",
    "                    np.array([int(self.target_id)])], names=('pipelineID','targetID'))\n",
    "        return update_time(_df) \n",
    "\n",
    "    def create(self,options={'any':0},ret_opt=False,create_dir=False,store=Store()):\n",
    "        _df = store.create('targets','target_id',self)\n",
    "        _opt = Options(options).create('target',int(_df.target_id),store=store)\n",
    "        \n",
    "        if create_dir:\n",
    "            _t = subprocess.run(['mkdir', '-p', str(self.relativepath[0])], stdout=subprocess.PIPE)\n",
    "        \n",
    "        if ret_opt:\n",
    "            return _df, _opt\n",
    "        else:\n",
    "            return _df       \n",
    "    \n",
    "    def get(target_id,store=Store()):\n",
    "        x = store.select('targets', 'target_id=='+str(target_id))\n",
    "        return x.loc[x.index.values[0]]\n",
    "\n",
    "\n",
    "class Configuration():\n",
    "    def __init__(self,name='',description='',\n",
    "                 target=Target().new()):\n",
    "        self.name = np.array([str(name)])\n",
    "        self.relativepath = np.array([str(target.relativepath[0])])\n",
    "        self.logpath = np.array([str(target.relativepath[0])+'/log_'+str(name)])\n",
    "        self.confpath = np.array([str(target.relativepath[0])+'/conf_'+str(name)])\n",
    "        self.rawpath = np.array([str(target.relativepath[0])+'/raw_'+str(name)])\n",
    "        self.procpath = np.array([str(target.relativepath[0])+'/proc_'+str(name)])\n",
    "        self.target_id = np.array([int(target.target_id)])\n",
    "        self.pipeline_id = np.array([int(target.pipeline_id)])\n",
    "        self.config_id = np.array([int(0)])\n",
    "        self.description = np.array([str(description)])        \n",
    "        self.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "        return None\n",
    "        \n",
    "    def new(self):\n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = pd.MultiIndex.from_arrays(arrays=[np.array([int(self.pipeline_id)]),\n",
    "                    np.array([int(self.target_id)]), np.array([int(self.config_id)])],\n",
    "                    names=('pipelineID','targetID','configID'))\n",
    "        return update_time(_df)        \n",
    "\n",
    "        \n",
    "    def create(self,params={'any':0},create_dir=False,ret_opt=False,store=Store()):\n",
    "        _df = store.create('configurations','config_id',self)\n",
    "        _params = Parameters(params).create(_df,store=store)\n",
    "        \n",
    "        if create_dir:\n",
    "            for _path in [self.rawpath[0],self.confpath[0],self.procpath[0],self.logpath[0]]:\n",
    "                _t = _t = subprocess.run(['mkdir', '-p', str(_path)], stdout=subprocess.PIPE)\n",
    "        \n",
    "        if ret_opt:\n",
    "            return _df, _params\n",
    "        else:\n",
    "            return _df    \n",
    "        \n",
    "    def get(config_id,store=Store()):\n",
    "        x = store.select('configurations', 'config_id=='+str(config_id)) \n",
    "        return x.loc[x.index.values[0]]\n",
    "    \n",
    "    \n",
    "    \n",
    "class DataProduct():\n",
    "    def __init__(self,filename='any',relativepath='',group='',\n",
    "                 configuration=Configuration().new(),\n",
    "                 data_type='',subtype='',filtername='',\n",
    "                 ra=0,dec=0,pointing_angle=0):\n",
    "        self.config_id = np.array([int(configuration.config_id)])\n",
    "        self.target_id = np.array([int(configuration.target_id)])\n",
    "        self.pipeline_id = np.array([int(configuration.pipeline_id)])\n",
    "        self.dp_id = np.array([int(0)])\n",
    "\n",
    "        self.filename = np.array([str(filename)])\n",
    "        self.relativepath = np.array([str(relativepath)])\n",
    "\n",
    "        _suffix = ' '\n",
    "        if '.' in filename:\n",
    "            _suffix = filename.split('.')[-1]\n",
    "        if _suffix not in ['fits','txt','head','cl',\n",
    "           'py','pyc','pl','phot','png','jpg','ps',\n",
    "           'gz','dat','lst','sh']:\n",
    "            _suffix = 'other'                                      \n",
    "        self.suffix = np.array([str(_suffix)])\n",
    "        \n",
    "        if not(data_type): data_type = _suffix\n",
    "        self.data_type = np.array([str(data_type)])\n",
    "        self.subtype = np.array([str(subtype)])\n",
    "\n",
    "        if group not in ['proc','conf','log','raw']:\n",
    "            group = 'other'\n",
    "        self.group = np.array([str('other')])\n",
    "\n",
    "        self.filtername = np.array([str(filtername)])\n",
    "        self.ra = np.array([float(ra)])\n",
    "        self.dec = np.array([float(dec)])\n",
    "        self.pointing_angle = np.array([float(pointing_angle)])\n",
    "        # self.tags = Options(tags) # meant to break\n",
    "        self.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "        return None\n",
    "\n",
    "    def new(self):        \n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = pd.MultiIndex.from_arrays(arrays=[np.array([int(self.pipeline_id)]),\n",
    "                    np.array([int(self.target_id)]), np.array([int(self.config_id)]),\n",
    "                    np.array([int(self.dp_id)])],\n",
    "                    names=('pipelineID','targetID','configID','dpID'))\n",
    "        return update_time(_df)\n",
    "\n",
    "    def create(self,options={'any':0},ret_opt=False,store=Store()):\n",
    "        _df = store.create('data_products','dp_id',self)\n",
    "        _opt = Options(options).create('data_product',int(_df.dp_id),store=store)\n",
    "        if ret_opt:\n",
    "            return _df, _opt\n",
    "        else:\n",
    "            return _df  \n",
    "        \n",
    "    def get(dp_id,store=Store()):\n",
    "        x = store.select('data_products', 'dp_id=='+str(dp_id)) \n",
    "        return x.loc[x.index.values[0]]\n",
    "    \n",
    "class Parameters():\n",
    "    def __init__(self,params={'any':0}):\n",
    "        self.__dict__ = params\n",
    "        return None\n",
    " \n",
    "    def new(self,config=Configuration().new()):\n",
    "        name = np.array(list(self.__dict__.keys()))\n",
    "        value = np.array(list(self.__dict__.values()))\n",
    "        _df = pd.DataFrame(data=np.array([name,value]).T,columns=\n",
    "                ['name','value']).sort_values('name')\n",
    "        \n",
    "        _config_id = np.repeat(int(config.config_id),len(name))\n",
    "        _target_id = np.repeat(int(config.target_id),len(name))\n",
    "        _pipeline_id = np.repeat(int(config.pipeline_id),len(name))\n",
    "        arrays = [_pipeline_id,_target_id,_config_id]\n",
    "        _df.index= pd.MultiIndex.from_arrays(arrays,\n",
    "                     names=('pipelineID','targetID','configID'))\n",
    "        return _df\n",
    "\n",
    "    def create(self,config=Configuration().new(),store=Store()):\n",
    "        _df = self.new(config)\n",
    "        with pd.HDFStore(str(store.path),'r+') as myStore:\n",
    "            myStore.append('parameters',_df,min_itemsize=_min_itemsize(_df))\n",
    "        return _df\n",
    "\n",
    "    def getParam(config_id=0,store=Store()):\n",
    "        config_id = int(config_id)\n",
    "        config = Configuration.get(int(config_id))\n",
    "        target_id = int(config.target_id)\n",
    "        pipeline_id = int(config.pipeline_id)\n",
    "        x = store.select('parameters').loc[pipeline_id,target_id,config_id] \n",
    "        if x.shape==(2,):\n",
    "            return dict(zip([x['name']],[x['value']]))\n",
    "        else:\n",
    "            return dict(zip(x['name'].values,x['value'].values))\n",
    "    \n",
    "    def addParam(config_id,key,value,store=Store()):\n",
    "        config_id = int(config_id)\n",
    "        _config = Configuration.get(config_id)\n",
    "        _params = Parameters.getParam(config_id)\n",
    "        _params[key] = value\n",
    "        return store.update('parameters',Parameters(_params).new(_config))\n",
    "    \n",
    "    \n",
    "class Task():\n",
    "    def __init__(self,name='any',\n",
    "                 pipeline=Pipeline().new(),\n",
    "                 nruns=0,run_time=0,\n",
    "                 is_exclusive=0):\n",
    "        self.name = np.array([str(name)])\n",
    "        self.pipeline_id = np.array([int(pipeline.pipeline_id)])\n",
    "        self.task_id = np.array([int(0)])\n",
    "        self.nruns = np.array([int(nruns)])\n",
    "        self.run_time = np.array([float(run_time)])\n",
    "        self.is_exclusive = np.array([bool(is_exclusive)])\n",
    "        self.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "        return None\n",
    "\n",
    "    def new(self):        \n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = pd.MultiIndex.from_arrays(arrays=[np.array([int(self.pipeline_id)]),\n",
    "                    np.array([int(self.task_id)])], names=('pipelineID','taskID'))\n",
    "        return update_time(_df)\n",
    "\n",
    "    def create(self,store=Store()):\n",
    "        _df = store.create('tasks','task_id',self)\n",
    "        return _df    \n",
    "        \n",
    "    def add_mask(task,source='any',name='any',value='0',store=Store()):\n",
    "        return Mask(task,source,name,value).create(store=store)\n",
    "        \n",
    "    def get(task_id,store=Store()):\n",
    "        x = store.select('tasks', 'task_id=='+str(task_id))\n",
    "        return x.loc[x.index.values[0]]    \n",
    "        \n",
    "        \n",
    "class Job():\n",
    "    def __init__(self,state='any',event_id=0,\n",
    "                 task=Task().new(),\n",
    "                 config=Configuration().new(),\n",
    "                 node=Node().new()):\n",
    "        self.state = np.array([str(state)])\n",
    "        self.job_id = np.array([int(0)])\n",
    "        self.event_id = np.array([int(event_id)])\n",
    "        self.task_id = np.array([int(task.task_id)])\n",
    "        self.config_id = np.array([int(config.config_id)])\n",
    "        self.node_id =  np.array([int(node.node_id)])\n",
    "        self.pipeline_id =  np.array([int(config.pipeline_id)])\n",
    "        self.starttime = pd.to_datetime(time.time(),unit='s')\n",
    "        self.endtime = pd.to_datetime(time.time(),unit='s')\n",
    "        self.timestamp = pd.to_datetime(time.time(),unit='s')\n",
    "        return None\n",
    "    \n",
    "    def new(self):\n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = update_time((pd.MultiIndex.from_arrays(arrays=\n",
    "                   [np.array([int(self.pipeline_id)]),\n",
    "                    np.array([int(self.task_id)]),\n",
    "                    np.array([int(self.config_id)]),\n",
    "                    np.array([int(self.event_id)]),\n",
    "                    np.array([int(self.job_id)])],\n",
    "                    names=('pipelineID','taskID','configID','eventID','jobID'))))\n",
    "        _df.endtime = _df.timestamp.copy()\n",
    "        return _df\n",
    "        \n",
    "    def create(self,options={'completed':0},ret_opt=False,store=Store()):\n",
    "        _df = store.create('jobs','job_id',self)\n",
    "        _opt = Options(options).create('job',int(_df.job_id),store=store)\n",
    "        if ret_opt:\n",
    "            return _df, _opt\n",
    "        else:\n",
    "            return _df   \n",
    "        \n",
    "    def get(job_id,store=Store()):\n",
    "        x = store.select('jobs', 'job_id=='+str(job_id)) \n",
    "        return x.loc[x.index.values[0]]    \n",
    "\n",
    "    def getEvent(job,\n",
    "                  name='any',value='0',jargs='0',\n",
    "                  options={'any':0},store=Store()):\n",
    "        return Event(name,value,jargs,job).create(options=options,store=store)\n",
    "    \n",
    "class Event():\n",
    "    def __init__(self,name='',value='',jargs='',job=Job().new()):\n",
    "        self.job_id = np.array([int(job.job_id)])\n",
    "        self.jargs = np.array([str(jargs)])\n",
    "        self.name   = np.array([str(name)])\n",
    "        self.value  = np.array([str(value)])\n",
    "        self.event_id  = np.array([int(0)])\n",
    "        return None\n",
    "    \n",
    "    def new(self):\n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = _df.event_id\n",
    "        return update_time(_df)\n",
    "    \n",
    "    def create(self,options={'any':0},ret_opt=False,store=Store()):\n",
    "        _df = store.create('events','event_id',self)\n",
    "        _opt = Options(options).create('event',int(_df.event_id),store=store)\n",
    "        if ret_opt:\n",
    "            return _df, _opt\n",
    "        else:\n",
    "            return _df   \n",
    "        \n",
    "    def get(event_id,store=Store()):\n",
    "        return store.select('events').loc[int(event_id)]\n",
    "    \n",
    "    def run_complete(event_id=0,store=Store()):\n",
    "        event = Event.get(int(event_id))\n",
    "        job_id = int(event.job_id)\n",
    "        jobOpt = Options.get('job',int(job_id))\n",
    "        jobOpt['completed'] = int(jobOpt['completed'])+1\n",
    "        return store.update('options',Options(jobOpt).new('job',job_id))\n",
    "\n",
    "class Mask():\n",
    "    def __init__(self,task=Task().new(),source='',name='',value=''):\n",
    "        self.source = np.array([str(source)])\n",
    "        self.name   = np.array([str(name)])\n",
    "        self.value  = np.array([str(value)])\n",
    "        self.task_id = np.array([int(task.task_id)])\n",
    "        self.mask_id = np.array([int(0)])\n",
    "        return None\n",
    "\n",
    "    def new(self):\n",
    "        _df = pd.DataFrame.from_dict(self.__dict__)\n",
    "        _df.index = _df.mask_id\n",
    "        return update_time(_df)\n",
    "    \n",
    "    def create(self,store=Store()):\n",
    "        return store.create('masks','mask_id',self)\n",
    "    \n",
    "    def get(mask_id,store=Store()):\n",
    "        return store.select('masks').loc[int(mask_id)]\n",
    "\n",
    "def Submit(task,job_id,event_id):\n",
    "    pid = task.pipeline_id\n",
    "    myPipe = Pipeline.get(pid)\n",
    "    swroot = myPipe.software_root\n",
    "    executable = swroot+'/'+task['name']\n",
    "    dataroot = myPipe.data_root\n",
    "    job = Job.get(int(job_id))\n",
    "    #subprocess.Popen([executable,'-e',str(event_id),'-j',str(job_id)],cwd=dataroot) # This line will work with an SQL backbone, but NOT hdf5, as 2 tasks running on the same hdf5 file will collide!\n",
    "    subprocess.run([executable,'-e',str(event_id),'-j',str(job_id)],cwd=dataroot)\n",
    "    return\n",
    "\n",
    "def fire(event):\n",
    "    event_name = event['name'].values[0]\n",
    "    event_value = event['value'].values[0]\n",
    "    event_id = event['event_id'].values[0]\n",
    "    #print(\"HERE \",event['name'].values[0],\" DONE\")\n",
    "    parent_job = Job.get(int(event.job_id))\n",
    "    conf_id = int(parent_job.config_id)\n",
    "    configuration = Configuration.get(conf_id)\n",
    "    pipeline_id = parent_job.pipeline_id\n",
    "    #print(pipeline_id)\n",
    "    alltasks =  Store().select('tasks',where=\"pipeline_id==\"+str(pipeline_id))\n",
    "    for i in range(alltasks.shape[0]):\n",
    "        task = alltasks.iloc[i]\n",
    "        task_id = task['task_id']\n",
    "        #print(task_id)\n",
    "        m = Store().select('masks',where=\"task_id==\"+str(task_id))\n",
    "        for j in range(m.shape[0]):\n",
    "            mask = m.iloc[j]\n",
    "            mask_name = mask['name']\n",
    "            mask_value = mask['value']\n",
    "    \n",
    "            #print(\"HERE\",event_name,mask_name,event_value,mask_value,\"DONE3\")\n",
    "            if (event_name == mask_name) & ((event_value == mask_value) | (mask_value=='*')):\n",
    "                taskname = task['name']\n",
    "                newjob = Job(task=task,config=configuration,event_id=event_id).create() #need to give this a configuration\n",
    "                job_id = int(newjob['job_id'].values[0])\n",
    "                event_id = int(event['event_id'].values[0])\n",
    "                print(taskname,\"-e\",event_id,\"-j\",job_id)\n",
    "                Submit(task,job_id,event_id) #pipeline should be able to run stuff and keep track if it completes\n",
    "                return\n",
    "\n",
    "def logprint(configuration,job,log_text):\n",
    "    target_id = configuration['target_id']#.values[0]\n",
    "    pipeline_id = configuration['pipeline_id']#.values[0]\n",
    "    print(\"T\",target_id,\"P\",pipeline_id)\n",
    "    myPipe = Pipeline.get(pipeline_id)\n",
    "    myTarg = Target.get(target_id)\n",
    "    conf_name = configuration['name']#.values[0]\n",
    "    targ_name = myTarg['name']\n",
    "    logpath = myPipe.data_root+'/'+targ_name+'/log_'+conf_name+'/'\n",
    "    job_id = job['job_id']\n",
    "    event_id = job['event_id']\n",
    "    task_id = job['task_id']\n",
    "    task = Task.get(task_id)\n",
    "    task_name = task['name']\n",
    "    logfile = task_name+'_j'+str(job_id)+'_e'+str(event_id)+'.log'\n",
    "    print(task_name,job_id,event_id,logpath)\n",
    "    try:\n",
    "     log = open(logpath+logfile, \"a\")\n",
    "    except:\n",
    "     log = open(logpath+logfile, \"w\")\n",
    "    log.write(log_text)\n",
    "    log.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Store().new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myUser = User('rubab').create()\n",
    "myUser = User('ben').create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cost': '1029', 'how_much': '11', 'what': 'this', 'where': 'Portland, OR'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch User\n",
    "myUser = User.get('rubab')\n",
    "\n",
    "# Specify User when creating Pipeline\n",
    "myPipe = Pipeline(user=myUser,name='test_pipe',\n",
    "                 description='Testing pipeline').create()\n",
    "\n",
    "# Specify Pipeline when creating Target\n",
    "myTarget = Target(name='test_target', pipeline=myPipe).create()\n",
    "\n",
    "# Specify Target when creating Config\n",
    "myConfig = Configuration(name='test_config',target=myTarget).create()\n",
    "\n",
    "# Specify Config when creating Parameters\n",
    "params={'a':0,'x':12,'note':'testing this'}\n",
    "\n",
    "myParams = Parameters(params).create(myConfig)\n",
    "\n",
    "# Add or update Parameters\n",
    "Parameters.addParam(int(myConfig.config_id),'annulus',12)\n",
    "Parameters.addParam(int(myConfig.config_id),'delta_annulus',8)\n",
    "\n",
    "# Specify Config when creating DataProduct\n",
    "\n",
    "myDP1 = DataProduct(filename='test_file1.fits',group='raw',\n",
    "                    configuration=myConfig,filtername='H158').create()\n",
    "myDP2 = DataProduct(filename='test_file23.txt',group='conf',\n",
    "                    configuration=myConfig,filtername='').create()\n",
    "myDP3 = DataProduct(filename='test_file34.cl',group='proc',\n",
    "                    configuration=myConfig,filtername='').create()\n",
    "myDP4 = DataProduct(filename='test_file62.log',group='log',\n",
    "                    configuration=myConfig,filtername='').create()\n",
    "\n",
    "# Specify Pipeline when creating Task\n",
    "myTask = Task('new_task',pipeline=myPipe).create()\n",
    "\n",
    "# Create mask only by adding to task\n",
    "_mask = Task.add_mask(myTask,'*','some_mask','task_name')\n",
    "_mask = Task.add_mask(myTask,'*','another_mask','other_name')\n",
    "\n",
    "# Specify task and config when creating job\n",
    "newJob = Job(task=myTask,config=myConfig).create()\n",
    "\n",
    "# Pass current Job when creating new Event\n",
    "newEvent = Job.getEvent(newJob,'something_happened',181,options={'what':'this','how_much':11})\n",
    "\n",
    "# Add or update Options\n",
    "Options.addOption('event',int(newEvent.event_id),'where','Seattle, WA')\n",
    "Options.addOption('event',int(newEvent.event_id),'cost',1172)\n",
    "\n",
    "# Check that add or update works\n",
    "anotherJob = Job(task=myTask,config=myConfig,\n",
    "            event_id=int(newEvent.event_id)).create()\n",
    "\n",
    "anotherEvent = Job.getEvent(anotherJob,'something_else_happened',\n",
    "               12, {'xaxis':[12,50],'yaxis':[-1,100],'cmap':'gamma'},\n",
    "               options=Options.get('event',int(newEvent.event_id)))\n",
    "\n",
    "Options.addOption('event',int(anotherEvent.event_id),'where','Portland, OR')\n",
    "\n",
    "Options.addOption('event',int(anotherEvent.event_id),'cost',1029)\n",
    "\n",
    "Options.get('event',int(newEvent.event_id))\n",
    "\n",
    "Options.get('event',int(anotherEvent.event_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Store().repack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Event.fire(event) creates jobs with nruns=-1\n",
    "backend_single.py finds those jobs and submits them to pool\n",
    "Event.run_complete(event) should change nruns to 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>config_id</th>\n",
       "      <th>data_type</th>\n",
       "      <th>dec</th>\n",
       "      <th>dp_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>filtername</th>\n",
       "      <th>group</th>\n",
       "      <th>pipeline_id</th>\n",
       "      <th>pointing_angle</th>\n",
       "      <th>ra</th>\n",
       "      <th>relativepath</th>\n",
       "      <th>subtype</th>\n",
       "      <th>suffix</th>\n",
       "      <th>target_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pipelineID</th>\n",
       "      <th>targetID</th>\n",
       "      <th>configID</th>\n",
       "      <th>dpID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fits</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>test_file1.fits</td>\n",
       "      <td>H158</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>fits</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-27 21:12:24.388375044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   config_id data_type  dec  dp_id  \\\n",
       "pipelineID targetID configID dpID                                    \n",
       "1          1        1        1             1      fits  0.0      1   \n",
       "\n",
       "                                          filename filtername  group  \\\n",
       "pipelineID targetID configID dpID                                      \n",
       "1          1        1        1     test_file1.fits       H158  other   \n",
       "\n",
       "                                   pipeline_id  pointing_angle   ra  \\\n",
       "pipelineID targetID configID dpID                                     \n",
       "1          1        1        1               1             0.0  0.0   \n",
       "\n",
       "                                  relativepath subtype suffix  target_id  \\\n",
       "pipelineID targetID configID dpID                                          \n",
       "1          1        1        1                           fits          1   \n",
       "\n",
       "                                                      timestamp  \n",
       "pipelineID targetID configID dpID                                \n",
       "1          1        1        1    2018-08-27 21:12:24.388375044  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Store().select('data_products',where='target_id=='+str(1)+'& suffix=='+'\"fits\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
